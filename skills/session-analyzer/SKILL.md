---
name: session-analyzer
description: |
  클로드 코드 세션 로그를 자동으로 분석하여 날짜별 활동 요약을 생성합니다.
  기술 스택, 작업 유형, 사고 과정, 인사이트를 추출하여 마크다운 리포트를 제공합니다.

  트리거 키워드:
  - /session-analyzer
  - "세션 분석", "활동 로그", "사용 내역", "로그 분석"
  - "오늘 뭐했지", "이번 주 활동", "최근 작업"
---

# 클로드 코드 세션 로그 자동 분석 Skill

이 Skill은 `~/.claude/projects/` 디렉토리에 저장된 JSONL 세션 로그를 파싱하여 날짜별 활동을 분석하고, JSON 형식의 분석 결과를 자동 생성합니다. 마크다운 리포트는 선택적으로 생성할 수 있습니다.

## 워크플로우

### 1단계: 분석 범위 확인

AskUserQuestion을 사용하여 사용자에게 분석할 기간을 확인합니다.

```yaml
questions:
  - question: "어떤 기간의 활동을 분석할까요?"
    header: "분석 기간"
    multiSelect: false
    options:
      - label: "오늘"
        description: "오늘 세션만 분석합니다."
      - label: "어제"
        description: "어제 세션만 분석합니다."
      - label: "최근 7일"
        description: "최근 일주일간의 모든 세션을 분석합니다."
      - label: "전체 기간"
        description: "저장된 모든 세션을 분석합니다."
      - label: "특정 날짜"
        description: "사용자가 지정한 날짜의 세션을 분석합니다."
```

사용자가 "특정 날짜"를 선택하면 다시 날짜를 입력받습니다(YYYY-MM-DD 형식).

**"전체 기간" 또는 "weekly" 키워드 감지 시:**

사용자가 "모든 날짜", "전체", "weekly" 등을 요청하면:
1. `find ~/.claude/projects/ -name "*.jsonl" -type f`로 전체 세션 파일 날짜 범위를 파악
2. `--date-range START END --weekly`로 실행하면 전체 기간이 합산된 **단일 결과**를 반환 (일자별 배열이 아님)
3. 결과는 `~/.claude/summaries/weekly/YYYY-MM-WN.json`에 저장 (시작일 기준 주차: 1-7일=W1, 8-14일=W2, 15-21일=W3, 22-28일=W4, 29일+=W5)

### 2단계: 분석 스크립트 실행

통합 분석 스크립트를 Bash로 실행하여 세션 데이터를 수집합니다. 이 스크립트는 JSONL 파싱, 기술 스택 분석, 작업 유형 분류, 워크플로우 패턴, 활용도 점수를 모두 계산하여 JSON으로 출력합니다. **JSON 파일은 기본적으로 자동 저장됩니다.**

**단일 날짜:**
```bash
python3 ~/.claude/skills/session-analyzer/utils/analyze_sessions.py --date YYYY-MM-DD
```
→ 자동 저장: `~/.claude/summaries/daily/YYYY-MM-DD.json`

**날짜 범위:**
```bash
python3 ~/.claude/skills/session-analyzer/utils/analyze_sessions.py --date-range YYYY-MM-DD YYYY-MM-DD
```
→ 자동 저장: `~/.claude/summaries/range/YYYY-MM-DD_to_YYYY-MM-DD.json`

**주간 분석 (--weekly):**
```bash
python3 ~/.claude/skills/session-analyzer/utils/analyze_sessions.py --date-range YYYY-MM-DD YYYY-MM-DD --weekly
```
→ 자동 저장: `~/.claude/summaries/weekly/YYYY-MM-WN.json` (시작일 기준 주차 계산: 1-7일=W1, 8-14일=W2, 15-21일=W3, 22-28일=W4, 29일+=W5)
→ **`--weekly` 플래그 사용 시**: 일자별 배열이 아닌 전체 기간 합산 **단일 결과**(dict)를 출력. 모든 세션을 하나로 모아 통계/점수/피드백을 계산.

**에러 처리:**
- 세션이 없으면 stderr로 에러 메시지가 출력되고 exit code 1 반환
- 이 경우 사용자에게 다른 날짜를 선택하도록 안내

**출력 JSON 주요 필드:**
- `date_range`: 분석 기간 (start, end)
- `summary`: 세션 수, 평균 메시지/도구 호출, 주요 작업 Top 3
- `usage_style`: 프롬프트 통계, 세션 규모 분포, 수정 요청 빈도
- `tool_usage`: Skills, Agents, Commands 사용 내역, Top 5 도구
- `scoring`: 총점, 등급, 4개 카테고리 점수
- `feedback`: 강점, 개선점, 컨텍스트 관리 팁
- `error_summary`: 에러율, 주요 에러, 대응 패턴
- `main_workflow`: 주요 워크플로우 패턴 (1개)
- `config_changes`: 스킬/커맨드/프로젝트 설정(CLAUDE.md, settings.json) 변경 이력. 각 항목에 `details` 배열 포함:
  - `.py` 파일: 새 함수의 docstring 설명 (예: `타임스탬프 변환 추가`). docstring 없으면 함수명만 표시
  - `.md` 파일: 코드 블록 제거 후 새 섹션 헤더 또는 자연어 줄 추출
  - 품질 필터: 경로/명령어/트리구조/콜론 종료/불완전 문장 자동 제거, 유사 중복 제거(75% 유사도)
  - 의미 있는 설명을 추출할 수 없는 경우 detail 자체를 생략 (빈 배열 허용)
  - 코드 줄 직접 덤프 금지 — 제3자가 읽을 수 있는 완결된 자연어 설명만 출력

**JSON 저장 경로 변경:**

기본적으로 `--output-json auto`가 적용됩니다. 경로를 직접 지정하거나 파일 저장을 생략할 수 있습니다:
```bash
# 직접 경로 지정
python3 ~/.claude/skills/session-analyzer/utils/analyze_sessions.py --date YYYY-MM-DD --output-json /path/to/output.json

# JSON 파일 저장 생략 (stdout 출력만)
python3 ~/.claude/skills/session-analyzer/utils/analyze_sessions.py --date YYYY-MM-DD --no-save
```

### 3단계: Skills/Commands/Sub Agent 설명 동적 수집

출력 템플릿의 Skills/Commands/Sub Agents 테이블에 설명을 채우기 위해, 각 항목의 설명을 **동적으로** 수집한다. 하드코딩된 매핑 테이블은 사용하지 않는다.

**Skills 설명 수집:**

```
1. 세션 로그에서 사용된 Skill 이름 목록 추출 (Skill 도구 호출의 `skill` 파라미터)
2. 각 스킬에 대해 ~/.claude/skills/[스킬명]/SKILL.md 파일을 Read로 읽기
3. frontmatter의 description 필드에서 첫 번째 줄(한 줄 요약)을 추출
4. 파일이 없거나 description이 없으면 "커스텀 스킬"로 표기
```

**Commands 설명 수집:**

```
1. 세션 로그에서 사용된 슬래시 커맨드 목록 추출 (사용자 메시지에서 /로 시작하는 빌트인 커맨드)
2. 분석 시점의 시스템 프롬프트에 로드된 skill 목록의 description 참조
3. 빌트인 커맨드(/compact, /clear 등)는 분석 시 AI가 자체 지식으로 한 줄 설명 생성
4. 알 수 없는 커맨드는 커맨드명 그대로 표시
```

**Sub Agent 설명 수집:**

```
1. 세션 로그에서 Task 도구 호출의 subagent_type과 description 파라미터 추출
2. description 파라미터가 있으면 그것을 한 줄 설명으로 사용
3. description이 없으면 분석 시 AI가 자체 지식으로 해당 agent 유형의 한 줄 설명 생성
4. Explore 에이전트는 항상 "프로젝트 구조 및 설정 탐색"으로 표기 (보안 가이드라인 준수)
```

> **핵심 원칙**: 하드코딩된 매핑 테이블 없이, 세션 로그의 메타데이터 + 스킬 파일의 description + AI 자체 지식을 조합하여 동적으로 설명을 채운다.

### 8단계: 마크다운 요약 생성 (선택)

사용자가 마크다운 리포트를 요청한 경우에만 Write 도구로 요약 파일을 생성합니다. 기본적으로는 JSON 파일만 저장하고, 분석 결과를 채팅으로 요약하여 보여줍니다.

**파일 경로:**
- 일일 요약: `~/.claude/summaries/daily/[YYYY-MM-DD].md`
- 주간 요약: `~/.claude/summaries/weekly/[YYYY]-W[WW].md`

**마크다운 템플릿:**

```markdown
# [YYYY-MM-DD] Claude Code 활동 요약

> 자동 생성: [생성 시간]

## 요약 통계

| 항목 | 값 |
|------|-----|
| 세션 수 | [N]개 |
| 평균 메시지 | [N]개/세션 |
| 평균 도구 호출 | [N]회/세션 |
| 주요 작업 | [코딩, 리팩토링, 디버깅 등 상위 3개] |

---

## 사용 스타일 분석

### 요청 패턴
- **평균 프롬프트 길이**: [N]자 (약 [N]단어)
- **스타일 분포**: 명령형 [N]% / 설명형 [N]% / 계획 기반 [N]%

### 세션 규모 분포
| 규모 | 세션 수 | 평균 턴 수 |
|------|---------|-----------|
| 대규모 (70-150턴) | [N]개 | [N]턴 |
| 중규모 (40-70턴) | [N]개 | [N]턴 |
| 소규모 (5-15턴) | [N]개 | [N]턴 |

### 수정 요청 빈도
- 초기 요청: [N]개 → 후속 수정: [N]개 (비율: [N]배)

---

## Claude Code 활용 방식

### 활용한 Skills & Agents
| 유형 | 이름 | 설명 | 횟수 |
|------|------|------|------|
| Skill | /commit | Git 커밋 자동화 | [N]회 |
| Agent | Explore | 코드베이스 탐색 전문 에이전트 | [N]회 |
| Command | /compact | 대화 컨텍스트 압축 | [N]회 |

### 주요 도구 (Top 5)
[Read] [N]회 | [Edit] [N]회 | [Bash] [N]회 | [Grep] [N]회 | [Write] [N]회

---

## 활용도 평가

### 종합 점수: [N]/100 ([등급])

| 카테고리 | 점수 | 평가 |
|----------|------|------|
| 의도 전달력 | [N]/25 | [한 줄 평가] |
| 작업 효율성 | [N]/30 | [한 줄 평가] |
| 도구 적합성 | [N]/25 | [한 줄 평가] |
| 워크플로우 성숙도 | [N]/20 | [한 줄 평가] |

---

## 잘하고 있는 점

- [강점 1]
- [강점 2]
- [강점 3]

---

## 개선이 필요한 점

- [개선점 1]
- [개선점 2]
- [개선점 3]

---

## 컨텍스트 관리 전략

1. **세션 분리**: 50턴 기준으로 작업 단위 분할
2. **CLAUDE.md 강화**: 코드 패턴, 체크리스트, 자주 하는 실수 추가
3. **auto-memory 활성화**: 세션 간 학습 축적
4. **점진적 요청**: 한 번에 전체 계획 대신 단계별 진행

---

## 에러 & 워크플로우 요약

- **에러율**: [N]% (총 [N]회 발생)
- **주요 에러**: [에러 유형 1], [에러 유형 2]
- **대응 패턴**: 즉시 수정 [N]% / 대안 접근 [N]%
- **주요 워크플로우**: [Read → Edit → Bash] ([N]회)

---

## 설정 변경 이력

| 유형 | 이름 | 동작 | 변경 횟수 |
|------|------|------|-----------|
| skill | [스킬명] | modified | [N]회 |
| command | [커맨드명] | created/modified | [N]회 |
| project_config | CLAUDE.md | modified | [N]회 |
| settings | settings.json | modified | [N]회 |

> config_changes가 빈 배열이면 이 섹션은 생략한다.

---

*이 요약은 `/session-analyzer` Skill로 자동 생성되었습니다.*
```

## 보안 가이드라인 (필수)

출력물은 다른 유저들과 공유될 수 있으므로, 아래 정보는 **절대 포함하지 않는다**:

| 금지 항목 | 예시 |
|----------|------|
| 프로젝트명/종류 | "웹 앱 프로젝트", "블로그 프로젝트", "이커머스" 등 일반화된 표현도 금지 |
| 파일 경로 | `src/components/Foo.tsx`, `app/api/bar/route.ts` |
| 커밋 메시지 | `feat: 로그인 기능 추가` |
| 세션 ID | `76539087-f46e-4e72-...` |
| 작업 디렉토리 | `/Users/username/workspace/...` |
| Git 브랜치명 | `main`, `feature/xxx` |
| 사용자명/경로 | `/Users/atheimuz/...` |
| API 키/토큰 | 인증 관련 문자열 |
| 파일 타입 섹션 | `.tsx`, `.ts` 등 확장자 나열 금지 |

**대체 방법:**
- 프로젝트명/종류 → **기록하지 않음** (어떤 프로젝트인지 식별 가능한 정보 일절 제외)
- 파일 경로 → 작업 유형으로 대체 ("코드 수정", "설정 변경")
- 커밋 메시지 → 작업 유형 ("설정 변경 커밋", "코드 수정 커밋")
- 수정 내용 → "N개 파일 수정", "N건 변경"
- 구체적 기능명 → 추상적 작업 설명 ("컴포넌트 수정", "API 작업" 등 프로젝트를 유추할 수 없는 표현만 허용)

## 클로드 코드 활용 분석 중점 항목

출력물의 핵심은 **사용자가 클로드 코드를 어떻게 활용했는지**이다:

1. **모드 활용**: Plan Mode, Accept Edits, 일반 모드 중 어떤 것을 사용했는가
2. **에이전트 활용**: Explore, Plan 에이전트를 어떻게 위임했는가
3. **Skills 활용**: /granular-commit, /commit 등 어떤 스킬을 사용했는가
4. **프롬프트 스타일**: 지시가 간결한가, 구체적인가, 개방형인가
5. **대화 흐름**: 한번에 끝내는가, 후속 지시로 다듬는가
6. **작업 위임 수준**: 세부 지시 vs 높은 수준 목표만 제시
7. **도구 활용 효율**: 어떤 도구를 얼마나 사용했고 어떤 용도였는가

## 🎯 활용도 평가 점수 계산 로직

### 핵심 철학

"기능을 많이 쓰면 좋다"가 아니라 **"작업에 적합한 방식으로 사용했는가"**를 평가한다. 간단한 작업을 간단하게 끝내는 것도 높은 점수이며, 복잡한 작업에서 적절한 도구를 활용하는 것도 높은 점수다. **"해당 없음"인 항목은 자동 만점** 처리하여, 작업 성격에 따라 불필요한 기능을 사용하지 않았다고 벌점을 받지 않는다.

### Step 1: 작업 복잡도 자동 분류

점수 계산 전에 세션의 작업 복잡도를 먼저 판단한다. "도구 적합성"과 "워크플로우 성숙도" 카테고리에서 복잡도별 기대치가 달라진다.

```yaml
경량 (Light):
  조건: 수정 파일 < 3 AND 도구 호출 < 15 AND 메시지 < 10
  특징: 단순 수정, 질문, 짧은 탐색
  기대 행동: 빠르게 끝내기. Sub Agent/Skills 불필요할 수 있음

중량 (Medium):
  조건: 수정 파일 3-10 OR 도구 호출 15-50 OR 메시지 10-30
  특징: 기능 구현, 리팩토링, 중간 규모 디버깅
  기대 행동: 적절한 탐색 도구 활용, 필요시 Sub Agent

중량급 (Heavy):
  조건: 수정 파일 > 10 OR 도구 호출 > 50 OR 메시지 > 30
  특징: 대규모 작업, 아키텍처 변경, 복잡한 디버깅
  기대 행동: Sub Agent 위임, 계획 수립, 컨텍스트 관리 적극 활용
```

### Step 2: 4개 카테고리 평가 (100점)

#### 1. 의도 전달력 (25점)

> 어떤 작업이든 명확한 지시는 중요하다. 작업 성격과 무관하게 보편적으로 적용.

**탐지 방법**:

| 시그널 | 탐지 방법 | 분석 대상 |
|--------|----------|----------|
| 수정 지시 비율 | 사용자 메시지에서 "다시", "아니", "그게 아니라", "원래대로", "취소", "되돌려" 등 correction 키워드 탐지 | user 메시지 content |
| 초기 컨텍스트 | 첫 사용자 메시지의 길이 및 구체성 (에러 메시지, 파일명, 기대 동작 포함 여부) | 첫 user 메시지 |
| 방향 일관성 | 후속 메시지가 같은 맥락 심화인지, 완전히 다른 요청으로 전환인지 | user 메시지 시퀀스 |

**점수 계산**:

```yaml
수정 지시 비율 (15점):
  correction_ratio = correction_keywords 포함 user 메시지 수 / 전체 user 메시지 수
  - 0~10%: 15점 (명확한 지시, 수정 거의 없음)
  - 10~25%: 10점 (보통)
  - 25%+: 5점 (빈번한 수정 → 초기 지시 개선 필요)

초기 컨텍스트 제공 (5점):
  first_msg_length = 첫 user 메시지 글자 수
  has_specifics = 에러 메시지/파일 참조/구체적 요구사항 포함 여부
  - 50자+ AND has_specifics: 5점
  - 30~50자 OR has_specifics: 3점
  - 30자 미만 AND !has_specifics: 1점

방향 일관성 (5점):
  topic_switches = 완전히 다른 주제로 전환된 횟수 (연속 메시지 간 키워드 겹침률로 판단)
  - 전환 0-1회: 5점
  - 전환 2-3회: 3점
  - 전환 4회+: 1점
```

#### 2. 작업 효율성 (30점)

> 목표 대비 얼마나 낭비 없이 작업을 수행했는가. 간단한 작업을 간단하게 끝내는 것도 높은 점수.

**탐지 방법**:

| 시그널 | 탐지 방법 | 분석 대상 |
|--------|----------|----------|
| 재작업 비율 | 같은 파일을 Edit/Write로 3회 이상 수정한 파일 수 / 전체 수정 파일 수 | Edit/Write 도구의 file_path |
| 도구 성공률 | tool_result에서 에러가 아닌 비율 | tool_result 내용 |
| 작업 완결 시그널 | 세션 후반부에 "완료", "done", "커밋", "확인", "잘 됩니다" 등 완료 키워드 | 마지막 3개 user 메시지 |

**점수 계산**:

```yaml
재작업 비율 (10점):
  rework_files = Edit/Write 3회+ 수정된 고유 파일 수
  total_files = Edit/Write로 수정된 고유 파일 수
  rework_ratio = rework_files / total_files (total_files=0이면 ratio=0)
  - 0~10%: 10점 (한번에 잘 수정)
  - 10~30%: 7점 (일부 재작업)
  - 30%+: 4점 (잦은 재작업 → 사전 분석 부족)
  - 수정 파일 없음 (탐색/질문 세션): 10점 (해당 없음 → 만점)

도구 성공률 (10점):
  success_rate = 에러 미포함 tool_result 수 / 전체 도구 호출 수
  - 90%+: 10점
  - 70~90%: 7점
  - 70% 미만: 4점

작업 완결 (10점):
  has_completion_signal = 세션 후반 30% 메시지에서 완료 키워드 존재 여부
  - 완료 시그널 있음: 10점
  - 없음 (진행중/탐색 세션): 7점 (경량 벌점만)
```

#### 3. 도구 적합성 (25점)

> **이 카테고리는 작업 복잡도에 따라 기대치가 달라진다.** 핵심 변경점.

**탐지 방법**:

| 시그널 | 탐지 방법 | 분석 대상 |
|--------|----------|----------|
| 전용 도구 우선 사용 | Bash 명령어에서 grep/cat/find/head/tail/sed/awk 사용 횟수 | Bash 도구의 command 입력 |
| 규모 대비 위임 적절성 | 작업 복잡도 vs Sub Agent/Skills 사용 여부 | Task/Skill 도구 호출 + 복잡도 |
| 변경 후 검증 | Edit/Write 후 Bash로 테스트/빌드/린트 실행 여부 | Edit/Write → Bash 시퀀스 |

**점수 계산**:

```yaml
전용 도구 우선 사용 (10점):
  bash_antipatterns = Bash에서 grep/cat/find/head/tail/sed/awk 사용 횟수
  - 0회: 10점 (전용 도구를 적절히 사용)
  - 1~3회: 7점 (가끔 Bash 사용)
  - 4회+: 3점 (전용 도구 활용 부족)

규모 대비 위임 적절성 (10점):  ← 복잡도별 분기
  IF 경량(Light):
    - Sub Agent 미사용: 10점 (적절 - 불필요한 위임 안 함)
    - Sub Agent 사용: 7점 (과잉이지만 감점 최소화)
  IF 중량(Medium):
    - Sub Agent 또는 적절한 도구 조합 사용: 10점
    - 직접 수동 처리: 7점
  IF 중량급(Heavy):
    - Explore/Plan 에이전트 활용: 10점
    - 에이전트 미사용, 수동 처리: 5점 (위임이 효율적이었을 상황)
    - 병렬 에이전트 활용: +2점 보너스 (최대 10점 캡)

변경 후 검증 (5점):  ← 수정 규모별 분기
  edit_count = Edit/Write 호출 수
  has_verification = Edit/Write 후 Bash(test/build/lint/run) 호출 존재
  IF edit_count >= 5:
    - 검증 있음: 5점
    - 검증 없음: 2점
  IF edit_count < 5:
    - 5점 (소규모 수정은 검증 선택적 → 자동 만점)
  IF edit_count == 0:
    - 5점 (해당 없음)
```

#### 4. 워크플로우 성숙도 (20점)

> 반복 작업의 자동화, 에러 대응, 세션 관리의 성숙도를 평가.

**탐지 방법**:

| 시그널 | 탐지 방법 | 분석 대상 |
|--------|----------|----------|
| 반복 작업 자동화 | Git 커밋 작업 시 /commit 등 스킬 사용 여부 | Skill 도구 호출 + Bash git 명령 |
| 에러 적응력 | 도구 실패 후 같은 도구 동일 입력 재시도 vs 다른 접근 | tool_use → tool_result(error) → 다음 tool_use |
| 컨텍스트 관리 | 긴 세션에서 /compact 또는 세션 분리 활용 | 복잡도 + /compact 사용 여부 |

**점수 계산**:

```yaml
반복 작업 자동화 (7점):
  has_git_commit = Bash에서 "git commit" 실행 여부
  has_commit_skill = /commit 또는 /granular-commit 사용 여부
  has_other_skills = 기타 스킬 사용 여부
  IF has_git_commit AND !has_commit_skill:
    - 4점 (수동 커밋 → 스킬 활용 가능)
  IF has_commit_skill OR has_other_skills:
    - 7점 (자동화 활용)
  IF !has_git_commit AND !has_commit_skill:
    - 7점 (해당 없음 → 만점. 커밋이 필요 없는 세션)

에러 적응력 (7점):
  same_error_retries = 같은 도구+유사 입력으로 연속 실패한 횟수 (3회+ 카운트)
  - 연속 실패 0건: 7점 (적응적 대응 또는 에러 없음)
  - 연속 실패 1건: 5점
  - 연속 실패 2건+: 3점 (같은 실수 반복)

컨텍스트 관리 (6점):  ← 복잡도별 분기
  IF 경량(Light):
    - 6점 (짧은 세션은 관리 불필요 → 자동 만점)
  IF 중량(Medium):
    - 6점 (보통 크기도 자동 만점)
  IF 중량급(Heavy):
    - /compact 사용 OR 적절한 세션 분리: 6점
    - 미사용: 3점 (긴 세션에서 컨텍스트 관리 권장)
```

### 평가 등급

| 점수 범위 | 등급 | 설명 |
|----------|------|------|
| 90-100 | S | Claude Code 마스터 |
| 75-89 | A | 숙련된 사용자 |
| 60-74 | B | 중급 사용자 |
| 40-59 | C | 초급 사용자 |
| 0-39 | D | 입문자 |

### 피드백 생성 로직

**잘한 점 (긍정적 피드백):**
- 각 카테고리에서 80%+ 점수인 항목의 구체적 행동 언급
- 예: "초기 메시지에서 에러 로그와 기대 동작을 함께 제공하여 한번에 정확한 수정이 이루어졌습니다"
- 예: "소규모 수정 작업을 Sub Agent 없이 빠르게 직접 처리했습니다"

**개선 포인트 (구체적 제안):**
- 각 카테고리에서 50% 미만인 항목의 개선 제안
- 단, **"해당 없음"으로 만점인 항목은 제외**
- 예: "같은 파일을 5회 이상 수정했습니다. 수정 전 파일을 먼저 Read로 확인하면 재작업을 줄일 수 있습니다"
- 예: "Bash에서 grep을 4회 사용했습니다. Grep 전용 도구를 사용하면 더 정확하고 빠릅니다"

## 분석 설정

```yaml
필터링 기준:
  최소_메시지_수: 3        # 너무 짧은 세션 제외
  최소_도구_호출_수: 1     # 도구를 한 번도 안 쓴 세션 제외

추출 제한:
  thinking_블록_최대: 5    # 세션당 최대 5개
  명령어_기록_최대: 20     # 세션당 최대 20개 Bash 명령어
  세션_샘플링_최대: 100    # 대용량 시 최근 100개만

키워드_대소문자_무시: true
```

## 에러 핸들링

1. **세션이 없는 경우**
   - 메시지: "선택한 기간에 세션이 없습니다."
   - 사용자에게 다른 날짜 선택 제안

2. **JSONL 파싱 오류**
   - 손상된 파일 스킵
   - 정상 파일만 분석
   - 최종 요약에 "일부 파일 파싱 실패" 표시

3. **Python 실행 실패**
   - Python 3.7+ 필요: `python3 --version`으로 확인
   - macOS: `brew install python3`

4. **빈 데이터**
   - 키워드 매칭 실패 시 "기타" 카테고리로 분류
   - 최소한의 기본 통계는 제공

## 성능 최적화

**대용량 로그 처리:**

1. **샘플링**
   - 100개 이상 세션 시 최근 100개만 분석
   - 또는 시간순으로 균등 샘플링

2. **병렬 처리**
   - Bash의 xargs로 파일별 병렬 파싱
   - 각 세션 독립적으로 분석 후 집계

3. **캐싱**
   - 이미 분석한 세션은 재분석 안 함
   - 메타데이터 캐시 파일 생성 고려

## 사용 예시

```
사용자: /session-analyzer
Claude: [날짜 선택 질문 표시]
사용자: 오늘
Claude: [분석 진행...]
Claude: ✅ 분석 완료! ~/.claude/summaries/daily/2026-02-14.json 생성됨
Claude: [채팅으로 분석 결과 요약 표시]
```

마크다운 리포트도 함께 생성하려면:

```
사용자: /session-analyzer 마크다운도 생성해줘
Claude: [분석 진행...]
Claude: ✅ 분석 완료!
  - JSON: ~/.claude/summaries/daily/2026-02-14.json
  - MD: ~/.claude/summaries/daily/2026-02-14.md
```

자연어로도 실행 가능:

```
사용자: 오늘 뭐했는지 요약해줘
Claude: [자동으로 /session-analyzer 실행]

사용자: 최근 7일 활동 분석해줘
Claude: [최근 7일 선택하여 실행]

사용자: 어제 작업 내역 보여줘
Claude: [어제 선택하여 실행]
```

## 향후 확장

- [ ] 주간/월간 요약 생성
- [ ] 시각화 (차트/그래프)
- [ ] 키워드 검색 기능
- [ ] 웹 대시보드
- [ ] AI 기반 심층 인사이트
